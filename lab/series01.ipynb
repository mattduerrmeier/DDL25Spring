{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdpE7AVVJ8Y7"
   },
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D76883dUJ8Y9"
   },
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9g51FQBJ8Y9"
   },
   "source": [
    "First, ensure you have cloned the [course repository](https://github.com/lydiaYchen/DDL25Spring).\n",
    "\n",
    "Then, open the [interactive notebook version](https://github.com/lydiaYchen/DDL25Spring/blob/main/lab/homework-1.ipynb) of this homework from your local copy.\n",
    "\n",
    "For part A, fill in the code and answers within the notebook and save your changes.\n",
    "\n",
    "For part B, create and archive the necessary Python/shell scripts together.\n",
    "\n",
    "Finally, upload the notebook and the archive to the assignment in ILIAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlnG-vKEJ8Y_"
   },
   "source": [
    "## Part A (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCN8I685J8Y_"
   },
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTRmcGyHJ8ZA"
   },
   "source": [
    "When not otherwise specified, use the following parameter values in experiment runs:\n",
    "- `nr_clients` (N): 100\n",
    "- `lr`: 0.01\n",
    "- `client_fraction` (C): 0.1\n",
    "- `nr_local_epochs` (E): 1\n",
    "- `batch_size` (B): 100\n",
    "- `nr_rounds`: 10\n",
    "- `iid`: True\n",
    "\n",
    "For all exercises, pass `seed = 10` to calls for splitting data, server initialization, or plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fy6aia4xJ8ZB"
   },
   "source": [
    "### Exercise A1: FedSGD with weights (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLAVgj-UJ8ZA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from hfl_complete import *\n",
    "\n",
    "n = 100\n",
    "lr = 0.01\n",
    "c = 0.1\n",
    "e = 1\n",
    "b = 100\n",
    "nr_rounds = 10\n",
    "iid = True\n",
    "seed = 10\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM1EzAXaJ8ZC"
   },
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fImXBoi7J8ZD"
   },
   "source": [
    "_(2 points)_ Implement a version of FedSGD that uses weights in its updates, like FedAvg, instead of the gradients from the version of the tutorials. The two FedSGD versions should have the same test accuracy after each round (with a tolerance of at most 0.02%). To show this, compare their output for the following two scenarios over *5 rounds*:\n",
    "- `lr = 0.01, client_subsets = split(100, True, ...), client_fraction = 0.5`\n",
    "- `lr = 0.1, client_subsets = split(50, False, ...), client_fraction = 0.2`\n",
    "\n",
    "*Tip:* You can use the existing FedAvg implementation to minimize the amount of code writing required.\n",
    "\n",
    "_(1 point)_ Explain in which cases (about the different parameters for decentralized learning) the two are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuJXWU8CJ8ZD"
   },
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOirssvAJ8ZE"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class FedSgdWeightServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        client_subsets: list[Subset],\n",
    "        client_fraction: float,\n",
    "        seed: int\n",
    "    ) -> None:\n",
    "        super().__init__(lr, -1, client_subsets, client_fraction, seed)\n",
    "        # no optimizer: we train locally this time\n",
    "        self.name = \"FedSGDWeight\"\n",
    "        # like in FedSGD, only 1 epoch\n",
    "        self.nr_local_epochs = 1\n",
    "        # we can reuse the clients from the FedAvg; just train on the full mini-batch for 1 epoch\n",
    "        self.clients = [\n",
    "            WeightClient(subset, lr, len(subset), self.nr_local_epochs)\n",
    "            for subset in client_subsets\n",
    "        ]\n",
    "\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.0\n",
    "        run_result = RunResult(\n",
    "            self.name,\n",
    "            self.nr_clients,\n",
    "            self.client_fraction,\n",
    "            self.batch_size, # -1\n",
    "            self.nr_local_epochs, # 1\n",
    "            self.lr,\n",
    "            self.seed,\n",
    "        )\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(\n",
    "                self.nr_clients, self.nr_clients_per_round, replace=False\n",
    "            )\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i] for i in indices_chosen_clients\n",
    "            )\n",
    "            chosen_adjusted_weights: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.0\n",
    "\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = (\n",
    "                    self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                )\n",
    "                client_weights = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_weights.append(\n",
    "                    [\n",
    "                        self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                        for tens in client_weights\n",
    "                    ]\n",
    "                )\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_weights: list[torch.Tensor] = [\n",
    "                torch.stack(x, dim=0).sum(dim=0) for x in zip(*chosen_adjusted_weights)\n",
    "            ]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zip_parameter_weight = zip(\n",
    "                    self.model.parameters(), averaged_chosen_weights\n",
    "                )\n",
    "                for server_parameter, client_weight in zip_parameter_weight:\n",
    "                    server_parameter[:] = client_weight.to(device=device)\n",
    "\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(\n",
    "                2 * (nr_round + 1) * self.nr_clients_per_round\n",
    "            )\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tlT1o4ZJ8ZE"
   },
   "source": [
    "#### Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DHTD6PHEJ8ZE",
    "outputId": "87b55f6d-4f3b-4f54-a27f-21549e37f8d7"
   },
   "outputs": [],
   "source": [
    "# scenario 1 FedSGD (Weights)\n",
    "lr = 0.01\n",
    "client_subsets = split(100, True, seed=seed)\n",
    "client_fraction = 0.5\n",
    "\n",
    "fedsgd_weight_server = FedSgdWeightServer(\n",
    "    lr=lr, client_subsets=client_subsets, client_fraction=client_fraction, seed=seed\n",
    ")\n",
    "# run for 5 rounds\n",
    "results_fedsgd_weight = fedsgd_weight_server.run(5)\n",
    "fedsgd_weight_df = results_fedsgd_weight.as_df()\n",
    "fedsgd_weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "aYWyYH7eJ8ZF",
    "outputId": "ff1ca0a4-3823-420c-e4dc-6c07686c792a"
   },
   "outputs": [],
   "source": [
    "# scenario 1: FedSGD (Gradient)\n",
    "lr = 0.01\n",
    "client_subsets = split(100, True, seed=seed)\n",
    "client_fraction = 0.5\n",
    "\n",
    "fedsgd_gradient_server = FedSgdGradientServer(\n",
    "    lr=lr, client_subsets=client_subsets, client_fraction=client_fraction, seed=seed\n",
    ")\n",
    "# run for 5 rounds\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(5)\n",
    "fedsgd_gradient_df = result_fedsgd_gradient.as_df()\n",
    "fedsgd_gradient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egYaNS4QJ8ZF"
   },
   "source": [
    "#### Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4rvaHMnvJ8ZF",
    "outputId": "ed7d368a-86e6-426c-fe81-ee24fc8dc478"
   },
   "outputs": [],
   "source": [
    "# scenario 2: FedSGD (Weights)\n",
    "lr = 0.1\n",
    "client_subsets = split(50, False, seed=seed)\n",
    "client_fraction = 0.2\n",
    "\n",
    "fedsgd_weight_server = FedSgdWeightServer(\n",
    "    lr=lr, client_subsets=client_subsets, client_fraction=client_fraction, seed=seed\n",
    ")\n",
    "# run for 5 rounds\n",
    "results_fedsgd_weight = fedsgd_weight_server.run(5)\n",
    "fedsgd_weight_df = results_fedsgd_weight.as_df()\n",
    "fedsgd_weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JOHEVNn5Lktf",
    "outputId": "64dd59b5-15b9-4dbd-d935-d49c2fd215a1"
   },
   "outputs": [],
   "source": [
    "# scenario 2: FedSGD (Gradient)\n",
    "lr = 0.1\n",
    "client_subsets = split(50, False, seed=seed)\n",
    "client_fraction = 0.2\n",
    "\n",
    "fedsgd_gradient_server = FedSgdGradientServer(\n",
    "    lr=lr, client_subsets=client_subsets, client_fraction=client_fraction, seed=seed\n",
    ")\n",
    "\n",
    "# run for 5 rounds\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(5)\n",
    "fedsgd_gradient_df = result_fedsgd_gradient.as_df()\n",
    "fedsgd_gradient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3rtRmTvs6xM"
   },
   "source": [
    "*Q: (1 point) Explain in which cases (about the different parameters for decentralized learning) the two are equivalent.*\n",
    "\n",
    "In FedSGD, we do the forward pass on the full batch (-1), compute gradients, and send the gradients to the server.\n",
    "The server then averages the gradients and does the optimization step. On the next run, it will send the new weights to the clients.\n",
    "In FedAvg, each client trains for n epoch on mini-batches (forward, backward, update). The weights after training are sent to the server. The server averages the weights. On the next run, it will send the new weights to the clients.\n",
    "\n",
    "In FedSGDWeight, we do the forward pass on the full batch, compute the gradients, do the optimization step and send back the weights to the clients.\n",
    "This can be seen as a FedSGD with local weight update, or a FedAvg with 1 epoch and no mini-batches.\n",
    "If we were to do FedSGDWeight with multiple Epochs, or with mini-batches, then this would become a FedAvg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4A8Fy-imJ8ZG"
   },
   "source": [
    "### Exercise A2: Client number & fraction (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KMxgiOvJ8ZG"
   },
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiT1ZfQtJ8ZG"
   },
   "source": [
    "_(2 points)_ Run the necessary experiments to fill in the following table showing the final message count and test accuracy of FedSGD and FedAvg for different total client numbers:\n",
    "\n",
    "| Algorithm | N   | C   | Message count | Test accuracy |\n",
    "| --------- | --- | --- | ------------- | ------------- |\n",
    "| FedSGD    | 10  | 0.1 | 20            | 42.87         |\n",
    "| FedAvg    | 10  | 0.1 | 20            | 93.2          |\n",
    "| FedSGD    | 50  | 0.1 | 100           | 43.43         |\n",
    "| FedAvg    | 50  | 0.1 | 100           | 87.71         |\n",
    "| FedSGD    | 100 | 0.1 | 200           | 42.74         |\n",
    "| FedAvg    | 100 | 0.1 | 200           | 80.89         |\n",
    "\n",
    "Is the relationship between the metrics and client numbers monotonous?\n",
    "\n",
    "_(2 points)_ Run the experiments to fill in the table when varying the fraction of clients used in every round:\n",
    "\n",
    "| Algorithm | N   | C    | Message count | Test accuracy |\n",
    "| --------- | --- | ---- | ------------- | ------------- |\n",
    "| FedSGD    | 100 | 0.01 | 20            | 41.01         |\n",
    "| FedAvg    | 100 | 0.01 | 20            | 75.47         |\n",
    "| FedSGD    | 100 | 0.1  | 200           | 42.74         |\n",
    "| FedAvg    | 100 | 0.1  | 200           | 80.89         |\n",
    "| FedSGD    | 100 | 0.2  | 400           | 42.68         |\n",
    "| FedAvg    | 100 | 0.2  | 400           | 81.64         |\n",
    "\n",
    "How does the observed pattern differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmZDMAxCJ8ZG"
   },
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPvYKcRSJ8ZG"
   },
   "outputs": [],
   "source": [
    "n = 100        # nr_clients (N)\n",
    "lr = 0.01      # learning rate (lr)\n",
    "c = 0.1        # client fraction (C)\n",
    "e = 1          # nr local epochs (E)\n",
    "b = 100        # batch size (B)\n",
    "nr_rounds = 10 # nr rounds\n",
    "iid = True     # independent and identically distributed\n",
    "seed = 10      # seed for data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "4uLhlrqEJ8ZH",
    "outputId": "81d72611-efd5-4879-ff5b-b9ac23f66d5b"
   },
   "outputs": [],
   "source": [
    "ex_a21_results = []\n",
    "\n",
    "c = 0.1\n",
    "for n in [10, 50, 100]:\n",
    "    client_subsets = split(n, iid=iid, seed=seed)\n",
    "    # FedSGD\n",
    "    fedsgd_gradient_server = FedSgdGradientServer(\n",
    "        lr=lr, client_subsets=client_subsets, client_fraction=c, seed=seed\n",
    "    )\n",
    "    result_fedsgd_gradient = fedsgd_gradient_server.run(nr_rounds=nr_rounds)\n",
    "    ex_a21_results.append(result_fedsgd_gradient.as_df().iloc[-1])\n",
    "\n",
    "    # FedAvg\n",
    "    fedavg_server = FedAvgServer(\n",
    "        lr=lr, batch_size=b, client_subsets=client_subsets, client_fraction=c, nr_local_epochs=e, seed=seed\n",
    "    )\n",
    "    result_fedavg = fedavg_server.run(nr_rounds=nr_rounds)\n",
    "    ex_a21_results.append(result_fedavg.as_df().iloc[-1])\n",
    "\n",
    "ex_a21_df = pd.concat(ex_a21_results, axis=1, ignore_index=True).T\n",
    "ex_a21_df.loc[: , [\"Algorithm\", \"N\", \"C\", \"Message count\", \"Test accuracy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "RHtAfPArJ8ZH",
    "outputId": "0f87d26c-1644-40e5-dd2c-59eb5a2dc693"
   },
   "outputs": [],
   "source": [
    "ex_a22_results = []\n",
    "\n",
    "n = 100\n",
    "for c in [0.01, 0.1, 0.2]:\n",
    "    client_subsets = split(n, iid=iid, seed=seed)\n",
    "    # FedSGD\n",
    "    fedsgd_gradient_server = FedSgdGradientServer(\n",
    "        lr=lr, client_subsets=client_subsets, client_fraction=c, seed=seed\n",
    "    )\n",
    "    result_fedsgd_gradient = fedsgd_gradient_server.run(nr_rounds=nr_rounds)\n",
    "    ex_a22_results.append(result_fedsgd_gradient.as_df().iloc[-1])\n",
    "\n",
    "    # FedAvg\n",
    "    fedavg_server = FedAvgServer(\n",
    "        lr=lr, batch_size=b, client_subsets=client_subsets, client_fraction=c, nr_local_epochs=e, seed=seed\n",
    "    )\n",
    "    result_fedavg = fedavg_server.run(nr_rounds=nr_rounds)\n",
    "    ex_a22_results.append(result_fedavg.as_df().iloc[-1])\n",
    "\n",
    "ex_a22_df = pd.concat(ex_a22_results, axis=1, ignore_index=True).T\n",
    "ex_a22_df.loc[: , [\"Algorithm\", \"N\", \"C\", \"Message count\", \"Test accuracy\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E38Zh4A7J8ZH"
   },
   "source": [
    "### Exercise A3: Local epoch count & (non-)IID data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYKjANgDJ8ZI"
   },
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6pgmjGGJ8ZI"
   },
   "source": [
    "_(1 point)_ Create a line plot of the accuracy after each round for the following algorithm variants:\n",
    "\n",
    "- FedSGD\n",
    "- FedAvg (E=1)\n",
    "- FedAvg (E=2)\n",
    "- FedAvg (E=4)\n",
    "\n",
    "How does FedAvg compare to FedSGD? What is the effect of increasing the work clients perform locally for each update in FedAvg?\n",
    "\n",
    "_(2 points)_ Make one line plot of FedSGD and FedAvg under an IID and non-IID split for 15 rounds (leaving all other parameter values as they previously mentioned default). How does the non-IID setting affect the accuracy achieved by the two algorithms? What is the difference in terms of the smoothness of learning?\n",
    "\n",
    "_(2 points)_ Make another plot for only non-IID splits, including the FedSGD and FedAvg configs from before, and add a version for each with a learning rate of 0.001 and client fraction of 0.5. How does the stability of the new variants compare to the old ones? Why do the changes in parameters have the observed effect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1OyEnA_J8ZI"
   },
   "source": [
    "#### Answer 1: FedAvg vs FedSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xc--6YaTJ8ZI",
    "outputId": "8ca23214-417a-43fd-94f0-ae1c8c8220cb"
   },
   "outputs": [],
   "source": [
    "n = 100        # nr_clients (N)\n",
    "lr = 0.01      # learning rate (lr)\n",
    "c = 0.1        # client fraction (C)\n",
    "e = 1          # nr local epochs (E)\n",
    "b = 100        # batch size (B)\n",
    "nr_rounds = 10 # nr rounds\n",
    "iid = True     # independent and identically distributed\n",
    "seed = 10      # seed for data generation\n",
    "\n",
    "ex_a3_results = []\n",
    "\n",
    "# FedSGD\n",
    "client_subsets = split(nr_clients=n, iid=iid, seed=seed)\n",
    "\n",
    "fedsgd_gradient_server = FedSgdGradientServer(\n",
    "    lr=lr, client_subsets=client_subsets, client_fraction=c, seed=seed\n",
    ")\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(nr_rounds=nr_rounds)\n",
    "ex_a3_results.append(result_fedsgd_gradient.as_df())\n",
    "\n",
    "\n",
    "# FedAvg (E = 1)\n",
    "client_subsets = split(nr_clients=n, iid=iid, seed=seed)\n",
    "\n",
    "fedavg_server = FedAvgServer(\n",
    "    lr=lr, batch_size=b, client_subsets=client_subsets, client_fraction=c, nr_local_epochs=1, seed=seed\n",
    ")\n",
    "result_fedavg = fedavg_server.run(nr_rounds=nr_rounds)\n",
    "ex_a3_results.append(result_fedavg.as_df())\n",
    "\n",
    "\n",
    "# FedAvg (E = 2)\n",
    "client_subsets = split(nr_clients=n, iid=iid, seed=seed)\n",
    "\n",
    "fedavg_server = FedAvgServer(\n",
    "    lr=lr, batch_size=b, client_subsets=client_subsets, client_fraction=c, nr_local_epochs=2, seed=seed\n",
    ")\n",
    "result_fedavg_2 = fedavg_server.run(nr_rounds=nr_rounds)\n",
    "ex_a3_results.append(result_fedavg_2.as_df())\n",
    "\n",
    "\n",
    "# FedAvg (E = 4)\n",
    "client_subsets = split(nr_clients=n, iid=iid, seed=seed)\n",
    "\n",
    "fedavg_server = FedAvgServer(\n",
    "    lr=lr, batch_size=b, client_subsets=client_subsets, client_fraction=c, nr_local_epochs=4, seed=seed\n",
    ")\n",
    "result_fedavg_4 = fedavg_server.run(nr_rounds=nr_rounds)\n",
    "ex_a3_results.append(result_fedavg_4.as_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "UQ1zVr81J8ZL",
    "outputId": "135a662e-63b3-4c17-f3e5-9174cf8a912c"
   },
   "outputs": [],
   "source": [
    "# Combined Plot\n",
    "\n",
    "df = pd.concat(ex_a3_results, ignore_index=True)\n",
    "df[\"Algorithm\"] = df[\"Algorithm\"] + f\" (E={df[\"E\"].astype(str)})\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 6))\n",
    "\n",
    "sns.lineplot(df, x=\"Round\", y=\"Test accuracy\", hue=\"Algorithm\", seed=seed, ax=ax)\n",
    "ax.set_xticks(df[\"Round\"].unique())\n",
    "ax.set_yticks(np.arange(0, 101, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwRHKQfdPoq6"
   },
   "source": [
    "Q: *How does FedAvg compare to FedSGD? What is the effect of increasing the work clients perform locally for each update in FedAvg?*\n",
    "\n",
    "FedAvg performs much better than FedSGD, even when doing only 1 Epoch.\n",
    "At each round of FedAvg, we are training on multiple clients for $E = \\{1, 2, 4\\}$ Epochs, then send the weights to update the model.\n",
    "Meanwhile, in FedSGD, we only do 1 round and send the gradients instead.\n",
    "\n",
    "Between the FedAvg runs, we see that a higher number of Epochs, resulting in more local work by the clients, leads to a better accuracy score.\n",
    "With an Epoch of 2 and 4, we obtain very close test accuracy at 10 rounds.\n",
    "However the clients must do twice the amount of work in the latter configuration.\n",
    "An Epoch of 2 leads to a increase of almost 10 percentage points, while only losing a small amount of accuracy compared to 4 Epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDf_kdDt-86F"
   },
   "source": [
    "#### Answer 2: FedSGD vs FedAvg under an IID and non-IID split (15 rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nt4wMjrMRd9P",
    "outputId": "acad21dc-0197-42d7-eaa8-8b8226ab8a4a"
   },
   "outputs": [],
   "source": [
    "n = 100        # nr_clients (N)\n",
    "lr = 0.01      # learning rate (lr)\n",
    "c = 0.1        # client fraction (C)\n",
    "e = 1          # nr local epochs (E)\n",
    "b = 100        # batch size (B)\n",
    "nr_rounds = 10 # nr rounds\n",
    "iid = True     # independent and identically distributed\n",
    "seed = 10      # seed for data generation\n",
    "\n",
    "# FedSGD with iid = True\n",
    "ex_a3_fedsgd_results = []\n",
    "client_subsets = split(nr_clients=n, iid=True, seed=seed)\n",
    "\n",
    "fedsgd_gradient_server = FedSgdGradientServer(\n",
    "    lr=lr, client_subsets=client_subsets, client_fraction=c, seed=seed\n",
    ")\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(nr_rounds=15)\n",
    "fedsgd_df = result_fedsgd_gradient.as_df()\n",
    "\n",
    "fedsgd_df[\"Algorithm\"] = fedsgd_df[\"Algorithm\"] + f\" (iid={True})\"\n",
    "ex_a3_fedsgd_results.append(fedsgd_df)\n",
    "\n",
    "\n",
    "# FedSGD with iid = False\n",
    "client_subsets = split(nr_clients=n, iid=False, seed=seed)\n",
    "\n",
    "fedsgd_gradient_server = FedSgdGradientServer(\n",
    "    lr=lr, client_subsets=client_subsets, client_fraction=c, seed=seed\n",
    ")\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(nr_rounds=15)\n",
    "fedsgd_df = result_fedsgd_gradient.as_df()\n",
    "fedsgd_df[\"Algorithm\"] = fedsgd_df[\"Algorithm\"] + f\" (iid={False})\"\n",
    "ex_a3_fedsgd_results.append(fedsgd_df)\n",
    "\n",
    "\n",
    "# FedAvg with iid = True\n",
    "ex_a3_fedavg_results = []\n",
    "client_subsets = split(nr_clients=n, iid=True, seed=seed)\n",
    "\n",
    "fedavg_server = FedAvgServer(\n",
    "    lr=lr, batch_size=b, client_subsets=client_subsets, client_fraction=c, nr_local_epochs=e, seed=seed\n",
    ")\n",
    "result_fedavg = fedavg_server.run(nr_rounds=15)\n",
    "fedavg_df = result_fedavg.as_df()\n",
    "fedavg_df[\"Algorithm\"] = fedavg_df[\"Algorithm\"] + f\" (iid={True})\"\n",
    "ex_a3_fedavg_results.append(fedavg_df)\n",
    "\n",
    "# FedAvg with iid = False\n",
    "client_subsets = split(nr_clients=n, iid=False, seed=seed)\n",
    "\n",
    "fedavg_server = FedAvgServer(\n",
    "    lr=lr, batch_size=b, client_subsets=client_subsets, client_fraction=c, nr_local_epochs=e, seed=seed\n",
    ")\n",
    "result_fedavg = fedavg_server.run(nr_rounds=15)\n",
    "fedavg_df = result_fedavg.as_df()\n",
    "fedavg_df[\"Algorithm\"] = fedavg_df[\"Algorithm\"] + f\" (iid={False})\"\n",
    "ex_a3_fedavg_results.append(fedavg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "O_iMR4tl0ELR",
    "outputId": "8f8b3b4f-e5c1-4527-f6e2-f6f8267b5493"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "ex_a3_fedsgd_df = pd.concat(ex_a3_fedsgd_results)\n",
    "sns.lineplot(ex_a3_fedsgd_df, x=\"Round\", y=\"Test accuracy\", hue=\"Algorithm\", seed=seed, ax=ax1)\n",
    "\n",
    "ax1.set_xticks(ex_a3_fedsgd_df[\"Round\"].unique())\n",
    "ax1.set_yticks(np.arange(0, 101, 10))\n",
    "ax1.set_title(\"FedSGD (IID/non-IID)\")\n",
    "\n",
    "ex_a3_fedavg_df = pd.concat(ex_a3_fedavg_results)\n",
    "sns.lineplot(ex_a3_fedavg_df, x=\"Round\", y=\"Test accuracy\", hue=\"Algorithm\", seed=seed, ax=ax2)\n",
    "\n",
    "ax2.set_xticks(ex_a3_fedavg_df[\"Round\"].unique())\n",
    "ax2.set_yticks(np.arange(0, 101, 10))\n",
    "ax2.set_title(\"FedAvg (IID/non-IID)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z40GtzDv_F93"
   },
   "source": [
    " Q: *How does the non-IID setting affect the accuracy achieved by the two algorithms? What is the difference in terms of the smoothness of learning?*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td1q_wqxWBPd"
   },
   "source": [
    "#### Answer 3: FedSGD vs FedAvg non-IID splits, with varying learning rates and client fractions\n",
    "\n",
    " (2 points) Make another plot for only non-IID splits, including the FedSGD and FedAvg configs from before, and add a version for each with a learning rate of 0.001 and client fraction of 0.5. How does the stability of the new variants compare to the old ones? Why do the changes in parameters have the observed effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "SpF_NACKFwGd",
    "outputId": "f988c82b-38e8-49aa-e0f3-a143c6074cf5"
   },
   "outputs": [],
   "source": [
    "n = 100        # nr_clients (N)\n",
    "lr = 0.01      # learning rate (lr)\n",
    "c = 0.1        # client fraction (C)\n",
    "e = 1          # nr local epochs (E)\n",
    "b = 100        # batch size (B)\n",
    "nr_rounds = 10 # nr rounds\n",
    "iid = True     # independent and identically distributed\n",
    "seed = 10      # seed for data generation\n",
    "\n",
    "ex_a3_fedsgd_non_idd_results = []\n",
    "client_subsets = split(nr_clients=n, iid=False, seed=seed)\n",
    "\n",
    "# config 1: default lr and default fraction\n",
    "fedsgd_gradient_server = FedSgdGradientServer(\n",
    "    lr=lr, client_subsets=client_subsets, client_fraction=c, seed=seed\n",
    ")\n",
    "fedsgd_df = fedsgd_gradient_server.run(nr_rounds=15).as_df()\n",
    "\n",
    "#ex_a3_fedsgd_non_idd_results.append()\n",
    "\n",
    "fedsgd_df[\"Algorithm\"] + f\"(lr={df[\"\"]})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "9RzF2DKCV-AM",
    "outputId": "3a18d901-f187-4d87-fcc2-b0b501e8a932"
   },
   "outputs": [],
   "source": [
    "\n",
    "# config 2: lr=0.001, fraction=0.5\n",
    "fedsgd_gradient_server = FedSgdGradientServer(\n",
    "    lr=0.001, client_subsets=client_subsets, client_fraction=0.5, seed=seed\n",
    ")\n",
    "ex_a3_fedsgd_non_idd_results.append(fedsgd_gradient_server.run(nr_rounds=15).as_df())\n",
    "\n",
    "## FedAvg with iid = False\n",
    "ex_a3_fedavg_non_idd_results = []\n",
    "\n",
    "client_subsets = split(nr_clients=n, iid=False, seed=seed)\n",
    "\n",
    "# config 1: default lr and default fraction\n",
    "fedavg_server = FedAvgServer(\n",
    "    lr=lr, batch_size=b, client_subsets=client_subsets, client_fraction=c, nr_local_epochs=e, seed=seed\n",
    ")\n",
    "ex_a3_fedavg_non_idd_results.append(fedavg_server.run(nr_rounds=15).as_df())\n",
    "\n",
    "# config 2: lr=0.001, fraction=0.5\n",
    "fedavg_server = FedAvgServer(\n",
    "    lr=0.001, batch_size=b, client_subsets=client_subsets, client_fraction=0.5, nr_local_epochs=e, seed=seed\n",
    ")\n",
    "ex_a3_fedavg_non_idd_results.append(fedavg_server.run(nr_rounds=15).as_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JOE2JBW_hL2"
   },
   "outputs": [],
   "source": [
    "# Plotting the two non-IDD results\n",
    "ex_a3_non_iid_df = pd.concat(ex_a3_non_iid_results, ignore_index=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 6))\n",
    "\n",
    "sns.lineplot(ex_a3_non_iid_df, x=\"Round\", y=\"Test accuracy\", hue=\"Algorithm\", seed=seed, ax=ax)\n",
    "ax.set_xticks(ex_a3_non_iid_df[\"Round\"].unique())\n",
    "ax.set_yticks(np.arange(0, 101, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHqb2Yz5_Tpq"
   },
   "source": [
    "Q: *How does the stability of the new variants compare to the old ones? Why do the changes in parameters have the observed effect?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xlN3vcSJ8ZL"
   },
   "source": [
    "## Part B (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WA6OOr79J8ZL"
   },
   "source": [
    "### Exercise B1: Microbatch Pipeline Model Parallelism (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-L9sQ3JJ8ZL"
   },
   "source": [
    "Implement pipeline parallelism with microbatches, as discussed during the lab.\n",
    "\n",
    "As with the other data/model parallelism examples, you will need a Python script for the nodes and a shell script to orchestrate execution.\n",
    "\n",
    "Be aware of the possibility of deadlocks: due to how `good` operates, it is possible to deadlock by having device 1 send $B_2$ to device 2 in the forward pass, and simultaneously, device 2 send $B_1$ in the backward pass.\n",
    "Since both operations will await a corresponding receive the training will stop indefinitely.\n",
    "\n",
    "Use `isend` & `irecv`, the asynchronous (non-blocking) versions of `send` & `recv` in `torch.distributed`.\n",
    "Add comments or text explaining how you expect your implementation to work and test that it runs for the same number of steps and model architecture as in class.\n",
    "\n",
    "Note that `torch.distributed`'s implementation of `gloo` does not currently support properly asynchronous communication even when using the corresponding primitives.\n",
    "Thus, you will not see the same improvements in speed as with a backend like `nccl`.\n",
    "\n",
    "You may also take advantage of the fact that `torch` gradients naturally accumulate if zeroed out.\n",
    "Also, scaling the loss by a constant is equivalent to scaling the resulting gradients by the same constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5bwRTMSJ8ZL"
   },
   "source": [
    "### Exercise B2: Joint Data & Model Parallelism (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enfo_aroJ8ZM"
   },
   "source": [
    "Implement a training setup that uses data and model parallelism together.\n",
    "\n",
    "Create 2 pipelines of 3 stages running sequentially, where each stage works with 3 sequential micro-batches.\n",
    "\n",
    "Once again, add comments or text explaining your implementation and test it on the setting that mimics those from the class.\n",
    "\n",
    "You can use groups from `torch.distributed` to handle operations that require interaction between a subset of more than two but less than all workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2A5AXi3J8ZM"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "D76883dUJ8Y9",
    "WCN8I685J8Y_",
    "fy6aia4xJ8ZB",
    "4A8Fy-imJ8ZG",
    "0xlN3vcSJ8ZL"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
